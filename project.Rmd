---
title: "COVID-19 Vaccination Rates and Google Search Data"
author: "Arianna Schmid and Stacey Frank"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    df_print: kable
bibliography: citations.bib
link_citations: true
linkcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

``` {r include = FALSE}
library(xml2)
library(rvest)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(tidyverse)
library(magrittr)
library(gtrendsR)
library(readxl)
library(knitr)
library(grid)
library(gridExtra)
library(lattice)

load("shared_work_space.RData")

```

# Introduction

Vaccines to control the Coronavirus Disease 2019 (COVID-19) became available to the public in the first half of 2021. Rejection and indecision towards being vaccinated is evident across the United States. The motivation for this study is to provide a better understanding of reasons for COVID-19 vaccine refusal in the United States. This can help public health messaging campaigns be more targeted and effective when promoting vaccination. 

Google data is useful for exploring this topic because there is previous research that people feel freer to search for socially stigmatized topics on Google than they would be to admit such opinions in a survey or another form of data collection. In his study of racial animus's relationship to voting behavior, Stephens-Davidowitz notes that Google searchers are likely to be alone and thus more likely to search for private topics [@stephens-davidowitz_cost_2014]. Since we are interested in understanding how myths and conspiracies are playing into people's choice to receive the vaccine or not, Google searches are a useful source of data about the prevalence and impact of these ideas. 

## Research Questions

Our primary research question is what is the relationship, if any, between state-level COVID-19 vaccine rates and the types of Google searches that are made about vaccines in each state? To assist in answering that question, we have two secondary research questions: 

1. Are vaccine myths more commonly searched for in states that also have low vaccination rates? 
2. Does the relationship between COVID vaccine rates and Google searches change between June and September 2021?

We will use Google search data, state level COVID vaccination rate information from the Centers for Disease Control, and state-level demographic information to address these questions. 

# Data Collection

## 1. Google Trends and Keywords

The Centers for Disease Control provides a list of the most common questions about the COVID-19 vaccine, including mainstream questions and myths [@cdc_covid-19_2021]. Similarly, the Mayo Clinic provides information on the most common myths surrounding the vaccine [@noauthor_covid-19_2021]. Using these two data sources, we constructed a list of 12 keyword search terms. It consists of the two general searches, "covid vaccine" and "covid vaccine near me", five mainstream questions, such as "covid vaccine side effects," and 5 myth-related searches such as "covid vaccine microchip." 

We created a vector called "k" to signify "keywords" and referenced this vector in later code to loop over the search terms for which we wanted to collect data. Note that each element in "k" will be renamed based on its index (hits.1, hits.2, ...hits.12) for code efficiency.

```{r eval = FALSE, include = FALSE}

# Gtrends keyword searches
k <- c( "covid vaccine", "covid vaccine near me", "covid vaccine safe", "covid vaccine ingredients", 
        "covid vaccine pregnant", "covid vaccine protect", "covid vaccine side effects", "covid vaccine microchip", 
        "covid vaccine dna", "covid vaccine fetal", "covid vaccine infertility", "covid vaccine magnet")

```

```{r echo = FALSE}
kable(k, col.names = c('Search Term'), caption = "Google Search Terms in Vector 'k'")
```


We are interested in studying the Google search hit rate for all 12 terms in "k" for all 50 states and Washington, D.C. Since vaccines were made available to states at different points in time, and the nature of people's concerns about the vaccine may have changed over time, we pulled search hit rates from 3 different time periods: 1/1/21-9/20/21, 4/1/21-6/20/21, and 7/1/21-9/20/21.The gtrendsR package was used to work with Google Trends queries. 

We created the custom function get.hit.results() to iterate through all the Google Trends queries we wanted to run without repeating code. The function takes in the date range as an argument, calls gtrends() once for each of the 12 search terms, and returns the hit results by state based on the given date range. The hit rates by state for each search term are then extracted from the list initially generated by the gtrendsr() query, and saved into a single tibble containing the hit rates for all 12 search terms for the specified time period. The function is called 3 times, once for each date range, and the result is saved in the 3 objects hits.results.jan, hits.results.june, and hits.results.sept.


```{r eval = FALSE}

#User-defined function to run all needed Google Trends queries

get.hits.results <-  function(date){
    for (i in 1:length(k)){
          new_frame <- paste("Keyword",i,sep = "")
          assign(new_frame, gtrends(k[i], geo = "US",
                   time = date, low_search_volume = T)
                 )
    }
    
    hits_results <- Keyword1$interest_by_region %>%              
      left_join(Keyword2$interest_by_region, by = "location") %>%
      left_join(Keyword3$interest_by_region, by = "location") %>%
      left_join(Keyword4$interest_by_region, by = "location") %>%
      left_join(Keyword5$interest_by_region, by = "location") %>%
      left_join(Keyword6$interest_by_region, by = "location") %>%
      left_join(Keyword7$interest_by_region, by = "location") %>%
      left_join(Keyword8$interest_by_region, by = "location") %>%
      left_join(Keyword9$interest_by_region, by = "location") %>%
      left_join(Keyword10$interest_by_region, by = "location") %>%
      left_join(Keyword11$interest_by_region, by = "location") %>%
      left_join(Keyword12$interest_by_region, by = "location") %>%
      as_tibble() %>%
      select(c(1,2,6,10,14,18,22,26,30,34,38,42,46))
    
    hits_results %<>% rename( hits.1 = hits.x, 
                          hits.2 = hits.y,
                          hits.3 = hits.x.x,
                          hits.4 = hits.y.y,
                          hits.5 = hits.x.x.x,
                          hits.6 = hits.y.y.y,
                          hits.7 = hits.x.x.x.x,
                          hits.8 = hits.y.y.y.y,
                          hits.9 = hits.x.x.x.x.x,
                          hits.10 = hits.y.y.y.y.y,
                          hits.11 = hits.x.x.x.x.x.x,
                          hits.12 = hits.y.y.y.y.y.y)
    print(hits_results)  
    
}

hits.results.jan <- get.hits.results("2021-01-1 2021-09-20")
hits.results.june <- get.hits.results("2021-04-1 2021-06-20")
hits.results.sept <- get.hits.results("2021-07-1 2021-09-20")
```

```{r echo = FALSE, eval= FALSE}

hits.results.jan %>%
  arrange(location)

hits.results.june %>%
  arrange(location)

hits.results.sept %>%
  arrange(location)

```

Next, we are interested in getting the count of states that actually have a Google Trends ranking for each search term. We do this to ensure we are using search terms that are popular enough to have generated a hit rate, which will allow us to actually conduct our analysis. We accomplish this through the user-created get.search.terms() function. This function takes the hits results object from get.hit.results() as an argument, and returns the total number of states that have a reported hit rate for each search term in "k". Again, the function is called 3 times for each time period, and results are saved to the objects search.terms.jan, search.terms.june, and search.terms.sept. As an example, we see in Table 3 that for April-June, "covid vaccine," "covid vaccine near me," and	"covid vaccine side effects" have reported hit rates in all 50 states and Washington DC. On the other hand, "covid vaccine microchip" was only searched often enough to generate a hit rate in 17 states. 


```{r eval = FALSE, echo = FALSE}
#create a data frame that lists the count of states that have a gtrends ranking for the specified search term
get.search.terms <- function(hits_results){
  j <- c("hits.1", "hits.2", "hits.3", "hits.4", 
        "hits.5", "hits.6", "hits.7", "hits.8", 
        "hits.9", "hits.10","hits.11","hits.12")

  search_terms <- apply(!is.na(hits_results), 2, sum) %>%
    as_tibble() %>%
    slice_tail(n=12) %>%
    cbind(j,k) %>%
    relocate(value,.after = k)
    
  search_terms %<>% rename(var_name = j, search = k, num_states = value)
  
  print(search_terms)
}

search.terms.jan <- get.search.terms(hits.results.jan)
search.terms.june <- get.search.terms(hits.results.june) 
search.terms.sept <- get.search.terms(hits.results.sept)
```

```{r echo = FALSE}

kable(
  search.terms.jan, 
  col.names = c('Variable Name', 'Search Term', 'Number of States with Hit Rate'), caption = "January-September: Number of States with Hit Rates by Search")

kable(
  search.terms.june, 
  col.names = c('Variable Name', 'Search Term', 'Number of States with Hit Rate'), caption = "April-June: Number of States with Hit Rates by Search")

kable(
  search.terms.sept, 
  col.names = c('Variable Name', 'Search Term', 'Number of States with Hit Rate'), caption = "July-September: Number of States with Hit Rates by Search")


```
## 2. Vaccination Rates

```{r eval = FALSE, echo = FALSE}
## Use RSocrata to pull down CDC COVID vaccine data using their API
## Dataset information available here: https://dev.socrata.com/foundry/data.cdc.gov/unsk-b7fc
## https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-Jurisdi/unsk-b7fc

cdc.df <- read.socrata(
  "https://data.cdc.gov/resource/unsk-b7fc.json",
  app_token = "vUEGablI1SjS2eGix6O89iNgH",
  email     = "stacey.m.frank@gmail.com",
  password  = "fN7E27&3K0Uf"
)

```


```{r eval = FALSE, echo = FALSE}
##Data formatting/cleaning for CDC dataset

str(cdc.df)

apply(is.na(cdc.df), 2, sum)

cdc.df <- cdc.df %>% 
     mutate_at(c(4:80), as.numeric)

cdc.df$mmwr_week <- as.numeric(cdc.df$mmwr_week)

apply(is.na(cdc.df), 2, sum)
```


```{r eval = FALSE, echo = FALSE}
# Drop rows for territories and federal entities; only retain 50 states and Washington, DC (Google trends only has data for these entities)al = false

table(cdc.df$location)


attach(cdc.df)
cdc.df.50 <-  cdc.df[ which (location!= "BP2" & location!= "DD2" & location!= "GU" & location!= "IH2" & location!= "LTC" & location!= "MH" & location!= "AS" & location!= "FM" & location!= "MP" & location!= "RP" & location!= "US" & location!= "VA2" & location!= "VI" & location!= "PR"),]
detach(cdc.df)

table(cdc.df.50$location)
```


```{r eval = FALSE, echo = FALSE}
# Recode responses in CDC location variable so it matches the format used in Google Trends data, in preparation for joining datasets

cdc.df.50$location[cdc.df.50$location == "AK"] <- "Alaska"
cdc.df.50$location[cdc.df.50$location == "AL"] <- "Alabama"
cdc.df.50$location[cdc.df.50$location == "AR"] <- "Arkansas"
cdc.df.50$location[cdc.df.50$location == "AZ"] <- "Arizona"
cdc.df.50$location[cdc.df.50$location == "CA"] <- "California"
cdc.df.50$location[cdc.df.50$location == "CO"] <- "Colorado"
cdc.df.50$location[cdc.df.50$location == "CT"] <- "Connecticut"
cdc.df.50$location[cdc.df.50$location == "DC"] <- "District of Columbia"
cdc.df.50$location[cdc.df.50$location == "DE"] <- "Delaware"
cdc.df.50$location[cdc.df.50$location == "FL"] <- "Florida"
cdc.df.50$location[cdc.df.50$location == "GA"] <- "Georgia"
cdc.df.50$location[cdc.df.50$location == "HI"] <- "Hawaii"
cdc.df.50$location[cdc.df.50$location == "IA"] <- "Iowa"
cdc.df.50$location[cdc.df.50$location == "ID"] <- "Idaho"
cdc.df.50$location[cdc.df.50$location == "IL"] <- "Illinois"
cdc.df.50$location[cdc.df.50$location == "IN"] <- "Indiana"
cdc.df.50$location[cdc.df.50$location == "KS"] <- "Kansas"
cdc.df.50$location[cdc.df.50$location == "KY"] <- "Kentucky"
cdc.df.50$location[cdc.df.50$location == "LA"] <- "Louisiana"
cdc.df.50$location[cdc.df.50$location == "MA"] <- "Massachusetts"
cdc.df.50$location[cdc.df.50$location == "MD"] <- "Maryland"
cdc.df.50$location[cdc.df.50$location == "ME"] <- "Maine"
cdc.df.50$location[cdc.df.50$location == "MI"] <- "Michigan"
cdc.df.50$location[cdc.df.50$location == "MN"] <- "Minnesota"
cdc.df.50$location[cdc.df.50$location == "MO"] <- "Missouri"
cdc.df.50$location[cdc.df.50$location == "MS"] <- "Mississippi"
cdc.df.50$location[cdc.df.50$location == "MT"] <- "Montana"
cdc.df.50$location[cdc.df.50$location == "NC"] <- "North Carolina"
cdc.df.50$location[cdc.df.50$location == "ND"] <- "North Dakota"
cdc.df.50$location[cdc.df.50$location == "NE"] <- "Nebraska"
cdc.df.50$location[cdc.df.50$location == "NH"] <- "New Hampshire"
cdc.df.50$location[cdc.df.50$location == "NJ"] <- "New Jersey"
cdc.df.50$location[cdc.df.50$location == "NM"] <- "New Mexico"
cdc.df.50$location[cdc.df.50$location == "NV"] <- "Nevada"
cdc.df.50$location[cdc.df.50$location == "NY"] <- "New York"
cdc.df.50$location[cdc.df.50$location == "OH"] <- "Ohio"
cdc.df.50$location[cdc.df.50$location == "OK"] <- "Oklahoma"
cdc.df.50$location[cdc.df.50$location == "OR"] <- "Oregon"
cdc.df.50$location[cdc.df.50$location == "PA"] <- "Pennsylvania"
cdc.df.50$location[cdc.df.50$location == "RI"] <- "Rhode Island"
cdc.df.50$location[cdc.df.50$location == "SC"] <- "South Carolina"
cdc.df.50$location[cdc.df.50$location == "SD"] <- "South Dakota"
cdc.df.50$location[cdc.df.50$location == "TN"] <- "Tennessee"
cdc.df.50$location[cdc.df.50$location == "TX"] <- "Texas"
cdc.df.50$location[cdc.df.50$location == "UT"] <- "Utah"
cdc.df.50$location[cdc.df.50$location == "VA"] <- "Virginia"
cdc.df.50$location[cdc.df.50$location == "VT"] <- "Vermont"
cdc.df.50$location[cdc.df.50$location == "WA"] <- "Washington"
cdc.df.50$location[cdc.df.50$location == "WI"] <- "Wisconsin"
cdc.df.50$location[cdc.df.50$location == "WV"] <- "West Virginia"
cdc.df.50$location[cdc.df.50$location == "WY"] <- "Wyoming"

table(cdc.df.50$location)

```


We now have data for our Google search hits from January-September, April-June, and July-September. Next, we are interested in finding the corresponding information on vaccination rates for each state. This data is acquired by using RSocrata to pull COVID vaccine data from the Centers for Disease Control website via their API. After pulling the data into R, we did some basic data cleaning, including converting variables to a numeric type and dropping rows for U.S. territories and federal entities for which we did not have corresponding Google Trends data. We also recoded the state variable, which previously used the two-letter postal code for state (AK, AZ, etc.), to use the full state name. This was done so that the CDC data could be joined with the Google Trends data by state. 

After cleaning, the datasets vax.June21 and vax.Sept21 are created, where vax.June21 will correspond to the Google Trends hit results from April-June, and vax.Sept21 will correspond to January-September and July-September Google Trends hit results. We are focusing on the vaccination rates in June and September 2021 because June is around the time when vaccines became widely available to anyone who wanted one, while September 21, 2021 is the day before boosters for some at-risk groups were approved by the CDC. By doing this, we are restricting our analysis to the time before boosters were available. Our variables of interest are series_complete_pop_pct, which is the percentage of the population in each state that has completed their vaccine series, and admin_per_100k, which is the number of vaccines administered in each state per 100,000 people. 

The tables below list the top 10 states by percent of the population fully vaccinated in June and September 2021. 

```{r include=FALSE}

x <- vax.June21 %>%
  select(location, series_complete_pop_pct, admin_per_100k) %>%
  arrange(desc(series_complete_pop_pct))

y <- vax.Sept21 %>%
  select(location, series_complete_pop_pct, admin_per_100k) %>%
  arrange(desc(series_complete_pop_pct))


```


```{r echo= FALSE}

kable(head(x, n = 10), col.names = c('State', 'Percent Pop. Fully vaccinated', 'Administered Per 100K'), caption = "Top 10 States for % Population Vaccinated: June 2021")

kable(head(y, n = 10), col.names = c('State', 'Percent Pop. Fully vaccinated', 'Administered Per 100K'), caption = "Top 10 States for % Population Vaccinated: September 2021")

```

```{r, eval = FALSE, echo = FALSE}
## Create two datasets for our vaccination dates of interest

vax.June21 <- cdc.df.50 %>%
  filter(date == "2021-06-21")
vax.Sept21 <- cdc.df.50 %>%
  filter(date == "2021-09-21")

```

## 3. State-level Demographics
We now have our search hit results and vaccine rates. Before studying any correlations, we consider certain state-level demographic factors that could potentially have an impact on our analysis. Data of interest includes state population counts, voter information, household income, age group, and race. 
  

```{r eval = FALSE, echo = FALSE}

## Scrape state population info from Wikipedia. Turn into a data frame called state_pop

paths_allowed("https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population")
url <- read_html("https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population")  
nds <- html_nodes(url, xpath = '//td[(((count(preceding-sibling::*) + 1) = 3) and parent::*)]')
state <- html_text(nds)
state <- gsub("\n","",state)
state <- str_trim(state)
state <- state[-c(31,53:60)]

nds2 <- html_nodes(url, xpath = '//td[(((count(preceding-sibling::*) + 1) = 4) and parent::*)]')
population <- html_text(nds2)
population <- gsub("\n","",population)
population <- gsub(",","",population)
population <- population[-c(31,53:60)]

state_pop <- as_tibble(cbind(state,population))
state_pop <- state_pop %>% arrange(state)
```


```{r eval = FALSE, echo = FALSE}

## Join state population data from above with the June 21 and September 21 data frames

state_pop <- rename(state_pop, location = state)

vax.June21 <- vax.June21 %>%
  left_join(state_pop, by = "location")
  
vax.Sept21 <- vax.Sept21 %>%
  left_join(state_pop, by = "location")

vax.Sept21 %>%
  select(location, population, administered, admin_per_100k)
```

```{r eval = FALSE, echo = FALSE}

## Percent of population by state that have been fully vaccinated as of September 21

vax.Sept21 %>%
  select(location, series_complete_pop_pct) %>%
  arrange(series_complete_pop_pct) %>%
  kable(col.names = c('State', 'Percent Pop. Fully vaccinated'), caption = " State Level Percent of Population Fully Vaccinated by September 2021")
```

State population numbers were web scraped from Wikipedia using Selector Gadget [@noauthor_list_2021]. These state counts were then joined with the vax.June21 and vax.Sept21 frames created in Part 2. In addition, information on the Trump vote share in the 2020 presidential election for each state was downloaded from the Cook Political Report [@noauthor_2020_nodate]. Unnecessary columns were deleted and columns of interest were renamed. The final spreadsheet was saved as vote.xlsx. 

Median household income information from the 2018 Current Population Survey was downloaded from the U.S. Census Bureau website and saved as med.income.xlsx [@noauthor_current_nodate]. Unnecessary columns were deleted and columns of interest were selected: state (location) and median income (med.income). 

Percent of state population by age group was pulled from the Kids Count Data Center [@noauthor_adult_nodate] The raw Excel data was downloaded. Columns from years 2011-2019 were deleted since we are focusing on the most recently available data, in this case 2020. The spread() function from the tidyr package was then used to reshape from long to wide so we can split up the categorical Age Group Variable into the 3 separate variables: ages 18 to 24, ages 25 to 64, and ages 65 and over. The final spreadsheet was saved as percent.age.xlsx.

Race data from the 2020 Current Population Survey was pulled as a csv file from the Kaiser Family Foundation website [@noauthor_population_2021]. It was then converted from CSV to xlsx, unnecessary columns were deleted, columns of interest were renamed, and reported percentages of <.01 were replaced with 0 to make all cell values integers. Categories for American Indian/Alaska Native, Native Hawaiian/Other Pacific Islander, and Multiple Races were combined into a single 'Other' race category. This was saved as State Race Data.xlsx.

These four excel files were loaded into the FOCD Github public repository. They were then joined together in R and saved as the object "cov" (for covariates). This object was then joined with the two CDC vaccine rate data frames created in Part 2 (vax.June21 or vax.Sept21). 



```{r eval = FALSE, echo = FALSE}

## Get state percentages of Trump voters info. Source is https://cookpolitical.com/2020-national-popular-vote-tracker.

getwd() 
# /Users/ariannaschmid/Desktop/SURVMETH 727/FOCD
setwd("/Users/ariannaschmid/Desktop/SURVMETH 727")

percent.rep <- read_excel("vote.xlsx", sheet = "Sheet1")
percent.rep %<>% select (state,rep_percent) %>% rename (pct.vote.rep = rep_percent, location = state) %>% arrange(location)

 
## Get median household income info from 2018. Source is https://www2.census.gov/programs-surveys/cps/tables/time-series/historical-income-households/h08.xls

med.income <- read_excel("med.income.xlsx", range = cell_cols(1:2), col_names = c("location","med.income") )

## Get percent of state population by age group info. Source is https://datacenter.kidscount.org/data/tables/6538-adult-population-by-age-group#detailed/2/2-53/false/574,1729,37,871,870,573,869,36,868,867/117,2801,2802,2803/13515,13516

percent.age <- read_excel("percent.age.xlsx", 
                          col_names = c("location","age.group","pct.state.pop"))
percent.age %<>% spread(key = age.group, value = pct.state.pop) %>%
                 rename("pct.18.to.24" = "18 to 24", "pct.25.to.64" = "25 to 64","pct.65.over" = "Ages 65 and over")

percent.age$pct.18.to.24 <- as.numeric(percent.age$pct.18.to.24)
percent.age$pct.25.to.64 <- as.numeric(percent.age$pct.25.to.64)
percent.age$pct.65.over <- as.numeric(percent.age$pct.65.over)

#Get percent of state population by race/ethnic group. Source is 2020 Current Population Survey via the KFF:
#https://www.kff.org/other/state-indicator/population-distribution-by-race-ethnicity-cps/?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D

percent.race <- read_excel("C:/Users/sfrank/Box/JPSM/SURV727-Fundamentals of Computing and Data Display/FOCD RStudio/State Race Data.xlsx", 
                          col_names = TRUE, col_types = NULL)

## Join 3 sets from above together. These are some covariates for the regression model
cov <- percent.rep %>% full_join(med.income, by = "location") %>% full_join(percent.age, by = "location") %>% full_join(percent.race, by = "location")

## Join covariates from above with the June 21 and September 21 data frames; same as we did with state population info from Wikipedia

vax.June21 <- vax.June21 %>%
  left_join(cov, by = "location")
  
vax.Sept21 <- vax.Sept21 %>%
  left_join(cov, by = "location")


## Arianna's code to fix tables. Don't rerun.
vax.June21 %<>% select(-c(pct.vote.rep.x,med.income.x,pct.18.to.24.x,pct.25.to.64.x,pct.65.over.x,
                         )) 
vax.June21 %<>% rename(pct.vote.rep = pct.vote.rep.y, med.income = med.income.y, pct.18.to.24 = pct.18.to.24.y,
                       pct.25.to.64 = pct.25.to.64.y, pct.65.over = pct.65.over.y)

vax.Sept21 %<>% select(-c(pct.vote.rep.x,med.income.x,pct.18.to.24.x,pct.25.to.64.x,pct.65.over.x,
                         )) 
vax.Sept21 %<>% rename(pct.vote.rep = pct.vote.rep.y, med.income = med.income.y, pct.18.to.24 = pct.18.to.24.y,
                       pct.25.to.64 = pct.25.to.64.y, pct.65.over = pct.65.over.y)

```


```{r eval = FALSE, echo = FALSE}
## Replace NAs in gtrends hit rates data frames with zero (assuming there is no hit rate because there aren't enough searches, so functionally it's zero)

hits.results.jan[is.na(hits.results.jan)] = 0
hits.results.june[is.na(hits.results.june)] = 0
hits.results.sept[is.na(hits.results.sept)] = 0
```

Finally, the three gtrends datasets from Part 1 (hits.results.jan, hits.results.june, hits.results.sept) are joined with the updated vax.June21 or vax.Sept21, depending on the dates the Trends are covering. A user-defined function called join.gtrends.vaccine() accomplishes this and saves the 3 final data sets as Jan01.analysis, Sept21.analysis, and June21.analysis. Now they are ready for analysis. 

```{r eval = FALSE}

## This function joins the gtrends datasets with vaccine info datasets

join.gtrends.vaccine <- function (hits.results.month,vax.month){
  
  month.analysis <- vax.month %>% 
      select(location,date, admin_per_100k, series_complete_pop_pct,
             pct.vote.rep, med.income, pct.18.to.24, pct.25.to.64, pct.65.over, 
             pct.white, pct.black, pct.hispanic, pct.asian, pct.other.multiple) %>% 
        full_join(hits.results.month, by = "location") %>%
        arrange(location)
  
  print(month.analysis)

}

Jan01.analysis <- join.gtrends.vaccine(hits.results.jan,vax.Sept21)   
Sept21.analysis <- join.gtrends.vaccine(hits.results.sept,vax.Sept21)
June21.analysis <- join.gtrends.vaccine(hits.results.june,vax.June21)
```

# Analysis

## 1. Correlation Analysis

The three data sets Jan01.analysis, Sept21.analysis, and June21.analysis are used as arguments for the user-defined function get.correlations() and results are saved to the three objects Jan01.correlations, Sept21.correlations, and June21.correlations respectively. This function calculates the correlation between each search term (as defined in vector "k") and series_complete_pop_pct (percentage of the population in each state that has completed their vaccine series) along with the p value.

```{r eval = FALSE}

## This function pulls the correlations for all 3 data sets 
get.correlations <- function(month.analysis){
      #Loop for correlations for each search term
      j <- c("hits.1", "hits.2", 
      "hits.3", "hits.4", 
      "hits.5", "hits.6", 
      "hits.7", "hits.8", 
      "hits.9", "hits.10",
      "hits.11","hits.12")
    
      correlations <- data.frame(estimate=numeric(26), p.value=numeric(26))
    
      for(i in 15:ncol(month.analysis)){
        test <- cor.test(month.analysis[, i], month.analysis$series_complete_pop_pct)
        correlations$estimate[i] = test$estimate
        correlations$p.value[i] = test$p.value
      }
    
      correlations %<>%
        slice_tail(n=12) %>%
        cbind(j,k) %>%
        relocate(estimate, p.value,.after = k)
        
      correlations %<>% rename(var_name = j, search = k)
    
      print(correlations)
}

Jan01.correlations <- get.correlations(Jan01.analysis)
Sept21.correlations <- get.correlations(Sept21.analysis)
June21.correlations <- get.correlations(June21.analysis)

```
Results from Jan01.correlations and June21.correlations show that the correlation patterns are fairly similar for January-September and for April-June. In both cases, the more mainstream searches are positively correlated, and the myth-related searches are negatively correlated (with the exception of April-June, where infertility has a small positive correlation).

On the other hand, correlation patterns from Sept21.correlations are very different. Our results show for July-September searches, nearly all the search terms have a negative correlation. This is likely because most people in states with high vaccination rates had already been vaccinated by July. As a result, in these states, there are less people searching for vaccine information after July. Therefore in general, more of the vaccine searches (of all types) were happening in low vaccine rate states during July-September. This explains why 'covid vaccine' searches are positively correlated with vaccine rates when looking at the overall January-September searches-- but when just looking at July-September, they are negatively correlated since vaccinated people were no longer searching for vaccine info(see Figure 1 below).
Table 7 shows these correlation patterns for all three time periods.

```{r echo = FALSE}

a <- Jan01.correlations %>% select(var_name,search,estimate) 
est <- cbind(a,June21.correlations$estimate,Sept21.correlations$estimate)

knitr::kable(est,
  col.names = c("var_name","search","Jan-Sept","Apr-June", "Jul-Sept"),           
  caption = 'Correlations Between Search Hits and % Population Vaccinated'
)
```

Figure 1 shows the different correlation patterns between searches for 'COVID Vaccine' and State Vaccination rates in two time periods. We see a statistically significant positive correlation for the entire span of January-September, and a negative correlation when we restrict ourselves to July-September.


```{r, echo = FALSE, fig.height = 4}
##Plotting of correlations

cor_plots = list()

#Jan-Sept Searches
# using series_complete_pop_pct as measure for state vaccination rate                
cor_plots$cor1 = ggplot(Jan01.analysis) + 
                geom_point(aes(hits.1, series_complete_pop_pct), color = '#24d0bc', size = 3) + 
                labs(y = "", x = "Search Volume") +
                ggtitle(" \n January-September") + 
                theme(axis.text=element_text(size=10), axis.title=element_text(size=10),
                      plot.title = element_text(hjust = 0.5, vjust = 0.5, size = 10))

ggsave("covid.correlation.Jan.png")

#July-September Searches
# using series_complete_pop_pct as measure for state vaccination rate                
cor_plots$cor2 = ggplot(Sept21.analysis) + 
                geom_point(aes(hits.1, series_complete_pop_pct), color = '#24d0bc', size = 3) + 
                labs( y = "", x = "Search Volume") +
                ggtitle(" \n July-September") +
                theme(axis.text=element_text(size=10), axis.title=element_text(size=10),
                 plot.title = element_text(hjust = 0.5, vjust = 0.5, size = 10 ))


ggsave("covid.correlation.Sept.png")

grid.arrange(cor_plots$cor1, cor_plots$cor2,
 ncol = 2, top="Figure 1: Correlations Between Searches for \n 'COVID Vaccine' and State Vaccination Rates",
 left = "State % Pop. Completed Vax Series"
 )
```

Still, there are very few cases where we have statistically significant correlations at level .05. For this reason, we will incorporate the social demographic variables from Data Collection Part 3 as covariates for a regression analysis.

## 2. Regression Analysis
Given the lack of significant results in our correlation analysis, we next sought to use linear regression to determine the primary predictors of state vaccination rates. 

```{r include = FALSE}
# Plotting and regression analysis

Jan01.analysis %>% select(series_complete_pop_pct, pct.vote.rep,med.income,
                          pct.18.to.24,pct.25.to.64,pct.65.over) %>%
                          plot()

##percent republican and median income seem to have a linear relationship with series_complete_pop_pct; age does not seem to have any relationship with vax rates

Jan01.analysis %>% select(series_complete_pop_pct, pct.white,pct.black,pct.hispanic,pct.asian,pct.other.multiple) %>% 
                          plot()

##None of the race variables seem to be related to vax rates


Jan01.analysis %>% select(series_complete_pop_pct, hits.1,hits.2,hits.3,hits.4) %>% 
                          plot()

#Hits1 is related; other plots are widely scattered

Jan01.analysis %>% select(series_complete_pop_pct, hits.5,hits.6,hits.7,hits.8) %>% 
                          plot()

#Hits5 has some relationship; others not so much

Jan01.analysis %>% select(series_complete_pop_pct, hits.9,hits.10,hits.11,hits.12) %>% 
                          plot()

#No strong relationships here
```
```{r echo = FALSE}

sc_plots = list()

sc_plots$sc1 = ggplot(Sept21.analysis) + geom_point(aes(pct.vote.rep, series_complete_pop_pct), color = '#24d0bc', size = 4) + 
      labs(y = "% Pop. Vax", x = "State Vote Share for Trump (2020)") +
      theme_classic()
sc_plots$sc2 = ggplot(Sept21.analysis) + geom_point(aes(med.income, series_complete_pop_pct), color = '#24d0bc', size = 4) + 
  labs(y = "% Pop. Vax", x = "State Median Income") +    
  theme_classic()
sc_plots$sc3 = ggplot(Sept21.analysis) + geom_point(aes(hits.1, series_complete_pop_pct), color = '#24d0bc', size = 4) + 
      labs(y = "% Pop. Vax", x = "Jan-Sept Search Volume for 'COVID Vaccine'") +
      theme_classic()

grid.arrange(sc_plots$sc1, sc_plots$sc2, sc_plots$sc3,
 ncol = 2, top="Predictor Variables Associated with State Vaccination Rates")

```

```{r}
##histogram of outcome variable

ggplot(Jan01.analysis) + geom_histogram(aes(series_complete_pop_pct), color = "black", fill = '#24d0bc', binwidth = 4, bins =8) + 
      ggtitle("Percent of Population Fully Vaccinated by State") + 
      labs(x = "State % Population Vaccinated") +
      theme_classic()

ggplot(Jan01.analysis) + geom_histogram(aes(admin_per_100k), color = "black", fill = '#24d0bc', binwidth = 7125, bins =8) + 
      ggtitle("Vaccines Administered Per 100,000 Residents by State") + 
      labs(x = "Vaccines Administered Per 100k Residents") +
      theme_classic()
```

```{r}
##Linear model

model1 <- lm(series_complete_pop_pct ~ pct.vote.rep + pct.white + pct.black + hits.1 + hits.2 + hits.3 + hits.4 + hits.5 + hits.6 + hits.7 + hits.8 + hits.9 + hits.10 + hits.11 + hits.12 , data = Jan01.analysis)

summary(model1)

#Check that residuals are normally distributed

hist(residuals(model1))

#Check for homoskedasticity in residual variances (looks ok)

plot(fitted(model1), residuals(model1))
abline(h = 0, lty = 2)

#Linear model with interaction
#When adding interaction between hits.1 and % who voted republican, the main effects and the interaction are all not significant. Need to think about what that means...

model2 <- lm(series_complete_pop_pct ~ pct.vote.rep + pct.black + hits.1  + hits.1*pct.vote.rep, data = Jan01.analysis)

summary(model2)
```

```{r eval = FALSE}
save.image(file = "shared_work_space.RData")
```

# Conclusion

Include a link to the github repository

# References
