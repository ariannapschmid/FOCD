---
title: "project"
author: "Arianna Schmid, Stacey Frank"
date: "10/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## SETUP
``` {r echo = FALSE}
library(xml2)
library(rvest)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(tidyverse)
library(magrittr)
library(gtrendsR)
```

``` {r}
# scraping educated questions from cdc website
paths_allowed("https://www.cdc.gov/coronavirus/2019-ncov/vaccines/faq.html")
url <- read_html("https://www.cdc.gov/coronavirus/2019-ncov/vaccines/faq.html")  
nds <- html_nodes(url, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "btn-link", " " ))]//span')
common <- html_text(nds)
common # scraped unnecessary contact info for cdc. Only need 1st 30 elements
common <- common[1:30] # the result is a list of 30 educated/common vaccine questions

# scraping myths/uneducated questions from cdc website
myths <- read_html("https://www.cdc.gov/coronavirus/2019-ncov/vaccines/facts.html") %>%
  html_nodes(xpath = '//*[(@id = "accordion-2-card-4")]//span | //*[(@id = "accordion-2-card-3")]//span |    //*[(@id = "accordion-2-card-2")]//span | //*[(@id = "accordion-2-card-1")]//span | //*[contains(concat( " ", @class, " " ), concat( " ", "h4", " " ))]//strong') %>% 
  html_text()
  myths # the result is a list of 11 uneducated questions/myths
  
  
# clean the lists:remove stopwords, turn into lowercase, remove blank space, and add + sign to set up for gtrends search afterwards
myths = tolower(myths)
all_stops <- c(stopwords("en"), "can","will","near","get","united states","use", "like")
myths_clean <- removeWords(myths,all_stops)
myths_clean %<>% str_trim()
myths_clean <- gsub("\\s+"," + ", myths_clean)
myths_clean
  
```

```{r}
# will the keywords below capture searches like "will the covid-19 vaccine damage my dna" and other variants of that question? or do I remove the addition sign?
#Info about keyword searches: https://github.com/PMassicotte/gtrendsR/issues/268

us <- gtrends(c("covid vaccine DNA"), geo = "US", 
               time = "2021-05-1 2021-06-29", low_search_volume = T)
plot(us) 
str(us)
us_time <- us$interest_over_time %>%
      as_tibble()
glimpse(us_time)
```

```{r}
#hits for search keyword by state
us_state <- us$interest_by_region %>%
      as_tibble()
glimpse(us_state)

#hits for search keyword by metro area
us_metro <- us$interest_by_dma %>%
      as_tibble()

#hits for search keyword by city
us_city <- us$interest_by_city %>%
      as_tibble()
```


```{r}
##Use RSocrata to pull down CDC COVID vaccine data using their API
##Dataset information available here: https://dev.socrata.com/foundry/data.cdc.gov/unsk-b7fc
##https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-Jurisdi/unsk-b7fc

cdc.df <- read.socrata(
  "https://data.cdc.gov/resource/unsk-b7fc.json",
  app_token = "vUEGablI1SjS2eGix6O89iNgH",
  email     = "stacey.m.frank@gmail.com",
  password  = "fN7E27&3K0Uf"
)


```