---
title: "project"
author: "Arianna Schmid, Stacey Frank"
date: "10/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## SETUP
``` {r echo = FALSE}
library(xml2)
library(rvest)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(tidyverse)
library(magrittr)
library(gtrendsR)
library(readxl)

load("shared_work_space.RData")

```

``` {r}
# scraping educated questions from cdc website
paths_allowed("https://www.cdc.gov/coronavirus/2019-ncov/vaccines/faq.html")
url <- read_html("https://www.cdc.gov/coronavirus/2019-ncov/vaccines/faq.html")  
nds <- html_nodes(url, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "btn-link", " " ))]//span')
common <- html_text(nds)
common # scraped unnecessary contact info for cdc. Only need 1st 30 elements
common <- common[1:30] # the result is a list of 30 educated/common vaccine questions

# scraping myths/uneducated questions from cdc website
myths <- read_html("https://www.cdc.gov/coronavirus/2019-ncov/vaccines/facts.html") %>%
  html_nodes(xpath = '//*[(@id = "accordion-2-card-4")]//span | //*[(@id = "accordion-2-card-3")]//span |    //*[(@id = "accordion-2-card-2")]//span | //*[(@id = "accordion-2-card-1")]//span | //*[contains(concat( " ", @class, " " ), concat( " ", "h4", " " ))]//strong') %>% 
  html_text()
  myths # the result is a list of 11 uneducated questions/myths
  
  
# clean the lists:remove stopwords, turn into lowercase, remove blank space, and add + sign to set up for gtrends search afterwards
library("tm")
myths = tolower(myths)
all_stops <- c(stopwords("en"), "can","will","near","get","united states","use", "like")
myths_clean <- removeWords(myths,all_stops)
myths_clean %<>% str_trim()
myths_clean <- gsub("\\s+"," + ", myths_clean)
myths_clean
  
```

```{r}

#Gtrends keyword searches
#Info about keyword searches: https://github.com/PMassicotte/gtrendsR/issues/268

k <- c("covid vaccine",
"covid vaccine near me",
"covid vaccine safe", 
"covid vaccine ingredients", 
"covid vaccine pregnant", 
"covid vaccine protect", 
"covid vaccine side effects", 
"covid vaccine microchip", 
"covid vaccine dna", 
"covid vaccine fetal", 
"covid vaccine infertility", 
"covid vaccine magnet")

get.hits.results <-  function(date){
    for (i in 1:length(k)){
          new_frame <- paste("Keyword",i,sep = "")
          assign(new_frame, gtrends(k[i], geo = "US",
                   time = date, low_search_volume = T)
                 )
    }
    
    hits_results <- Keyword1$interest_by_region %>%              
      left_join(Keyword2$interest_by_region, by = "location") %>%
      left_join(Keyword3$interest_by_region, by = "location") %>%
      left_join(Keyword4$interest_by_region, by = "location") %>%
      left_join(Keyword5$interest_by_region, by = "location") %>%
      left_join(Keyword6$interest_by_region, by = "location") %>%
      left_join(Keyword7$interest_by_region, by = "location") %>%
      left_join(Keyword8$interest_by_region, by = "location") %>%
      left_join(Keyword9$interest_by_region, by = "location") %>%
      left_join(Keyword10$interest_by_region, by = "location") %>%
      left_join(Keyword11$interest_by_region, by = "location") %>%
      left_join(Keyword12$interest_by_region, by = "location") %>%
      as_tibble() %>%
      select(c(1,2,6,10,14,18,22,26,30,34,38,42,46))
    
    hits_results %<>% rename( hits.1 = hits.x, 
                          hits.2 = hits.y,
                          hits.3 = hits.x.x,
                          hits.4 = hits.y.y,
                          hits.5 = hits.x.x.x,
                          hits.6 = hits.y.y.y,
                          hits.7 = hits.x.x.x.x,
                          hits.8 = hits.y.y.y.y,
                          hits.9 = hits.x.x.x.x.x,
                          hits.10 = hits.y.y.y.y.y,
                          hits.11 = hits.x.x.x.x.x.x,
                          hits.12 = hits.y.y.y.y.y.y)
    print(hits_results)  
    
}

hits.results.jan <- get.hits.results("2021-01-1 2021-09-20")
hits.results.june <- get.hits.results("2021-04-1 2021-06-20")
hits.results.sept <- get.hits.results("2021-07-1 2021-09-20")

#create a data frame that lists the count of states that have a gtrends ranking for the specified search term
get.search.terms <- function(hits_results){
 j <- c("hits.1", 
"hits.2", 
"hits.3", 
"hits.4", 
"hits.5", 
"hits.6", 
"hits.7", 
"hits.8", 
"hits.9", 
"hits.10",
"hits.11",
"hits.12")

search_terms <- apply(!is.na(hits_results), 2, sum) %>%
  as_tibble() %>%
  slice_tail(n=12) %>%
  cbind(j,k) %>%
  relocate(value,.after = k)
  
search_terms %<>% rename(var_name = j, search = k, num_states = value)

print(search_terms)
  
}

search.terms.jan <- get.search.terms(hits.results.jan)
search.terms.june <- get.search.terms(hits.results.june) 
search.terms.sept <- get.search.terms(hits.results.sept)

```


```{r}
##Use RSocrata to pull down CDC COVID vaccine data using their API
##Dataset information available here: https://dev.socrata.com/foundry/data.cdc.gov/unsk-b7fc
##https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-Jurisdi/unsk-b7fc

cdc.df <- read.socrata(
  "https://data.cdc.gov/resource/unsk-b7fc.json",
  app_token = "vUEGablI1SjS2eGix6O89iNgH",
  email     = "stacey.m.frank@gmail.com",
  password  = "fN7E27&3K0Uf"
)

```


```{r}
##Data formatting/cleaning for CDC dataset

str(cdc.df)

apply(is.na(cdc.df), 2, sum)

cdc.df <- cdc.df %>% 
     mutate_at(c(4:80), as.numeric)

cdc.df$mmwr_week <- as.numeric(cdc.df$mmwr_week)

apply(is.na(cdc.df), 2, sum)
```


```{r}
#Drop rows for territories and federal entities; only retain 50 states and Washington, DC (Google trends only has data for these entities)

table(cdc.df$location)


attach(cdc.df)
cdc.df.50 <-  cdc.df[ which (location!= "BP2" & location!= "DD2" & location!= "GU" & location!= "IH2" & location!= "LTC" & location!= "MH" & location!= "AS" & location!= "FM" & location!= "MP" & location!= "RP" & location!= "US" & location!= "VA2" & location!= "VI" & location!= "PR"),]
detach(cdc.df)

table(cdc.df.50$location)
```


```{r}
#Recode responses in CDC location variable so it matches the format used in Google Trends data, in preparation for joining datasets

cdc.df.50$location[cdc.df.50$location == "AK"] <- "Alaska"
cdc.df.50$location[cdc.df.50$location == "AL"] <- "Alabama"
cdc.df.50$location[cdc.df.50$location == "AR"] <- "Arkansas"
cdc.df.50$location[cdc.df.50$location == "AZ"] <- "Arizona"
cdc.df.50$location[cdc.df.50$location == "CA"] <- "California"
cdc.df.50$location[cdc.df.50$location == "CO"] <- "Colorado"
cdc.df.50$location[cdc.df.50$location == "CT"] <- "Connecticut"
cdc.df.50$location[cdc.df.50$location == "DC"] <- "District of Columbia"
cdc.df.50$location[cdc.df.50$location == "DE"] <- "Delaware"
cdc.df.50$location[cdc.df.50$location == "FL"] <- "Florida"
cdc.df.50$location[cdc.df.50$location == "GA"] <- "Georgia"
cdc.df.50$location[cdc.df.50$location == "HI"] <- "Hawaii"
cdc.df.50$location[cdc.df.50$location == "IA"] <- "Iowa"
cdc.df.50$location[cdc.df.50$location == "ID"] <- "Idaho"
cdc.df.50$location[cdc.df.50$location == "IL"] <- "Illinois"
cdc.df.50$location[cdc.df.50$location == "IN"] <- "Indiana"
cdc.df.50$location[cdc.df.50$location == "KS"] <- "Kansas"
cdc.df.50$location[cdc.df.50$location == "KY"] <- "Kentucky"
cdc.df.50$location[cdc.df.50$location == "LA"] <- "Louisiana"
cdc.df.50$location[cdc.df.50$location == "MA"] <- "Massachusetts"
cdc.df.50$location[cdc.df.50$location == "MD"] <- "Maryland"
cdc.df.50$location[cdc.df.50$location == "ME"] <- "Maine"
cdc.df.50$location[cdc.df.50$location == "MI"] <- "Michigan"
cdc.df.50$location[cdc.df.50$location == "MN"] <- "Minnesota"
cdc.df.50$location[cdc.df.50$location == "MO"] <- "Missouri"
cdc.df.50$location[cdc.df.50$location == "MS"] <- "Mississippi"
cdc.df.50$location[cdc.df.50$location == "MT"] <- "Montana"
cdc.df.50$location[cdc.df.50$location == "NC"] <- "North Carolina"
cdc.df.50$location[cdc.df.50$location == "ND"] <- "North Dakota"
cdc.df.50$location[cdc.df.50$location == "NE"] <- "Nebraska"
cdc.df.50$location[cdc.df.50$location == "NH"] <- "New Hampshire"
cdc.df.50$location[cdc.df.50$location == "NJ"] <- "New Jersey"
cdc.df.50$location[cdc.df.50$location == "NM"] <- "New Mexico"
cdc.df.50$location[cdc.df.50$location == "NV"] <- "Nevada"
cdc.df.50$location[cdc.df.50$location == "NY"] <- "New York"
cdc.df.50$location[cdc.df.50$location == "OH"] <- "Ohio"
cdc.df.50$location[cdc.df.50$location == "OK"] <- "Oklahoma"
cdc.df.50$location[cdc.df.50$location == "OR"] <- "Oregon"
cdc.df.50$location[cdc.df.50$location == "PA"] <- "Pennsylvania"
cdc.df.50$location[cdc.df.50$location == "RI"] <- "Rhode Island"
cdc.df.50$location[cdc.df.50$location == "SC"] <- "South Carolina"
cdc.df.50$location[cdc.df.50$location == "SD"] <- "South Dakota"
cdc.df.50$location[cdc.df.50$location == "TN"] <- "Tennessee"
cdc.df.50$location[cdc.df.50$location == "TX"] <- "Texas"
cdc.df.50$location[cdc.df.50$location == "UT"] <- "Utah"
cdc.df.50$location[cdc.df.50$location == "VA"] <- "Virginia"
cdc.df.50$location[cdc.df.50$location == "VT"] <- "Vermont"
cdc.df.50$location[cdc.df.50$location == "WA"] <- "Washington"
cdc.df.50$location[cdc.df.50$location == "WI"] <- "Wisconsin"
cdc.df.50$location[cdc.df.50$location == "WV"] <- "West Virginia"
cdc.df.50$location[cdc.df.50$location == "WY"] <- "Wyoming"

table(cdc.df.50$location)

```


```{r}
# visualize doses administered over time for entire US

cdc.df.50 %>%
  group_by(date) %>%
  summarize(administered = sum(administered)) %>%
  ggplot() +
  geom_line(mapping = aes(x = date, y = administered))

```


```{r}
## Create two datasets for our vaccination dates of interest
## Might not use the June dataset in the end

vax.June21 <- cdc.df.50 %>%
  filter(date == "2021-06-21")


vax.Sept21 <- cdc.df.50 %>%
  filter(date == "2021-09-21")

```


```{r}

## Scrape state population info from Wikipedia. Turn into a data frame called state_pop

paths_allowed("https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population")
url <- read_html("https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population")  
nds <- html_nodes(url, xpath = '//td[(((count(preceding-sibling::*) + 1) = 3) and parent::*)]')
state <- html_text(nds)
state <- gsub("\n","",state)
state <- str_trim(state)
state <- state[-c(31,53:60)]

nds2 <- html_nodes(url, xpath = '//td[(((count(preceding-sibling::*) + 1) = 4) and parent::*)]')
population <- html_text(nds2)
population <- gsub("\n","",population)
population <- gsub(",","",population)
population <- population[-c(31,53:60)]

state_pop <- as_tibble(cbind(state,population))
state_pop <- state_pop %>% arrange(state)
```


```{r}

## Join state population data from above with the June 21 and September 21 data frames

state_pop <- rename(state_pop, location = state)

vax.June21 <- vax.June21 %>%
  left_join(state_pop, by = "location")
  
vax.Sept21 <- vax.Sept21 %>%
  left_join(state_pop, by = "location")

vax.Sept21 %>%
  select(location, population, administered, admin_per_100k)
```
```{r}

## Percent of population by state that have been fully vaccinated as of September 21

vax.Sept21 %>%
  select(location, series_complete_pop_pct) %>%
  arrange(series_complete_pop_pct)
```


```{r}

## Get state percentages of Trump voters info. Source is https://cookpolitical.com/2020-national-popular-vote-tracker.

getwd() 
# /Users/ariannaschmid/Desktop/SURVMETH 727/FOCD
setwd("/Users/ariannaschmid/Desktop/SURVMETH 727")

percent.rep <- read_excel("/Users/ariannaschmid/Desktop/SURVMETH 727/vote.xlsx", sheet = "Sheet1")
percent.rep %<>% select (state,rep_percent) %>% rename (pct.vote.rep = rep_percent, location = state) %>% arrange(location)

 
## Get median household income info from 2018. Source is https://www2.census.gov/programs-surveys/cps/tables/time-series/historical-income-households/h08.xls

med.income <- read_excel("/Users/ariannaschmid/Desktop/SURVMETH 727/med.income.xlsx", range = cell_cols(1:2), col_names = c("location","med.income") )

## Get percent of state population by age group info. Source is https://datacenter.kidscount.org/data/tables/6538-adult-population-by-age-group#detailed/2/2-53/false/574,1729,37,871,870,573,869,36,868,867/117,2801,2802,2803/13515,13516

percent.age <- read_excel("/Users/ariannaschmid/Desktop/SURVMETH 727/percent.age.xlsx", 
                          col_names = c("location","age.group","pct.state.pop"))
percent.age %<>% spread(key = age.group, value = pct.state.pop) %>%
                 rename("pct.18.to.24" = "18 to 24", "pct.25.to.64" = "25 to 64","pct.65.over" = "Ages 65 and over")

percent.age$pct.18.to.24 <- as.numeric(percent.age$pct.18.to.24)
percent.age$pct.25.to.64 <- as.numeric(percent.age$pct.25.to.64)
percent.age$pct.65.over <- as.numeric(percent.age$pct.65.over)

#Get percent of state population by race/ethnic group. Source is 2020 Current Population Survey via the KFF:
#https://www.kff.org/other/state-indicator/population-distribution-by-race-ethnicity-cps/?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D

percent.race <- read_excel("C:/Users/sfrank/Box/JPSM/SURV727-Fundamentals of Computing and Data Display/FOCD RStudio/State Race Data.xlsx", 
                          col_names = TRUE, col_types = NULL)

## Join 3 sets from above together. These are some covariates for the regression model
cov <- percent.rep %>% full_join(med.income, by = "location") %>% full_join(percent.age, by = "location") %>% full_join(percent.race, by = "location")

## Join covariates from above with the June 21 and September 21 data frames; same as we did with state population info from Wikipedia

vax.June21 <- vax.June21 %>%
  left_join(cov, by = "location")
  
vax.Sept21 <- vax.Sept21 %>%
  left_join(cov, by = "location")


## Arianna's code to fix tables. Don't rerun.
vax.June21 %<>% select(-c(pct.vote.rep.x,med.income.x,pct.18.to.24.x,pct.25.to.64.x,pct.65.over.x,
                         )) 
vax.June21 %<>% rename(pct.vote.rep = pct.vote.rep.y, med.income = med.income.y, pct.18.to.24 = pct.18.to.24.y,
                       pct.25.to.64 = pct.25.to.64.y, pct.65.over = pct.65.over.y)

vax.Sept21 %<>% select(-c(pct.vote.rep.x,med.income.x,pct.18.to.24.x,pct.25.to.64.x,pct.65.over.x,
                         )) 
vax.Sept21 %<>% rename(pct.vote.rep = pct.vote.rep.y, med.income = med.income.y, pct.18.to.24 = pct.18.to.24.y,
                       pct.25.to.64 = pct.25.to.64.y, pct.65.over = pct.65.over.y)

```


```{r}
## Replace NAs in gtrends hit rates data frames with zero (assuming there is no hit rate because there aren't enough searches, so functionally it's zero)

hits.results.jan[is.na(hits.results.jan)] = 0
hits.results.june[is.na(hits.results.june)] = 0
hits.results.sept[is.na(hits.results.sept)] = 0
```


```{r}

## This function joins the gtrends dataset with vaccine info dataset
join.gtrends.vaccine <- function (hits.results.month,vax.month){
  
  month.analysis <- vax.month %>% 
      select(location,date, admin_per_100k, series_complete_pop_pct,
             pct.vote.rep, med.income, pct.18.to.24, pct.25.to.64, pct.65.over, 
             pct.white, pct.black, pct.hispanic, pct.asian, pct.other.multiple) %>% 
        full_join(hits.results.month, by = "location") %>%
        arrange(location)
  
  print(month.analysis)

}

Jan01.analysis <- join.gtrends.vaccine(hits.results.jan,vax.Sept21)   
Sept21.analysis <- join.gtrends.vaccine(hits.results.sept,vax.Sept21)
June21.analysis <- join.gtrends.vaccine(hits.results.june,vax.June21)
```


```{r}
##Correlation analysis

# using series_complete_pop_pct as measure for state vaccination rate                
ggplot(Sept21.analysis, aes(hits.1, series_complete_pop_pct)) + geom_point() + 
      labs(y = "% of pop that completed vaccine series", x = "Search Volume") +
      ggtitle("Searches for vaccine safety info versus vaccine rates by State ")

plot(Sept21.analysis$hits.1,Sept21.analysis$series_complete_pop_pct,las = 1)

cor(x = Sept21.analysis$hits.1, y = Sept21.analysis$series_complete_pop_pct, use = "complete.obs")

cor.test(x = Sept21.analysis$hits.1,y = Sept21.analysis$series_complete_pop_pct)

# using admin_per_100k as measure for state vaccination rate  
plot(Sept21.analysis$hits.1,Sept21.analysis$admin_per_100k,las = 1)

cor(x = Sept21.analysis$hits.1,y = Sept21.analysis$admin_per_100k, use = "complete.obs")

cor.test(x = Sept21.analysis$hits.1,y = Sept21.analysis$admin_per_100k)

```

```{r}

## This function pulls the correlations for all 3 data sets 
get.correlations <- function(month.analysis){
      #Loop for correlations for each search term
      j <- c("hits.1", "hits.2", 
      "hits.3", "hits.4", 
      "hits.5", "hits.6", 
      "hits.7", "hits.8", 
      "hits.9", "hits.10",
      "hits.11","hits.12")
    
      correlations <- data.frame(estimate=numeric(26), p.value=numeric(26))
    
      for(i in 15:ncol(month.analysis)){
        test <- cor.test(month.analysis[, i], month.analysis$series_complete_pop_pct)
        correlations$estimate[i] = test$estimate
        correlations$p.value[i] = test$p.value
      }
    
      correlations %<>%
        slice_tail(n=12) %>%
        cbind(j,k) %>%
        relocate(estimate, p.value,.after = k)
        
      correlations %<>% rename(var_name = j, search = k)
    
      print(correlations)

}

Jan01.correlations <- get.correlations(Jan01.analysis)
Sept21.correlations <- get.correlations(Sept21.analysis)
June21.correlations <- get.correlations(June21.analysis)

```

```{r}
# Plotting and regression analysis

Jan01.analysis %>% select(series_complete_pop_pct, pct.vote.rep,med.income,
                          pct.18.to.24,pct.25.to.64,pct.65.over,
                          pct.white,pct.black,pct.hispanic,pct.asian,pct.other.multiple,
                          hits.1,hits.2,hits.3) %>% plot()


```

```{r}
save.image(file = "shared_work_space.RData")
```
