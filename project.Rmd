---
title: "COVID-19 Vaccination Rates and Google Search Data"
author: "Arianna Schmid and Stacey Frank"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    df_print: kable
bibliography: citations.bib
link_citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

``` {r include = FALSE}
library(xml2)
library(rvest)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(tidyverse)
library(magrittr)
library(gtrendsR)
library(readxl)
library(knitr)

load("shared_work_space.RData")

```

# Introduction

Vaccines to control the coronavirus disease 2019 (COVID-19) became available to the public in the first half of 2021. Rejection and indecision towards being vaccinated is evident across the United States.The motivation for this study is to provide a better understanding of reasons for COVID-19 vaccine refusal in the United States. This can help public health messaging campaigns be more targeted and effective when promoting vaccination. 

Google data is useful for exploring this topic because there is previous research that people feel freer to Google socially stigmatized topics than they would be to admit such opinions in a survey or other form of data collection. As a result, our primary research question is what is the relationship, if any, between state-level COVID-19 vaccine rates and the types of Google searches that are made about vaccines? In particular, are vaccine myths more commonly searched for in states that also have low vaccination rates? A secondary question we investigate is does the relationship between COVID vaccine rates and Google searches change between June and September 2021?

# Data Collection

## 1. Google Trends and Keywords
The CDC provides lists of the most common questions about the COVID-19 vaccine [@cdc_covid-19_2021]. Similarly, the Mayo Clinic provides information on the most common myths surrounding the vaccine[@noauthor_covid-19_2021]. Using these two data sources, a list of 12 keyword search terms was constructed. We call this list "k" to signify "keywords". It consists of the two general searches "covid vaccine" and "covid vaccine near me", five meainstream searches such as "covid vaccine side effects," and 5 myth-related searches such as "covid vaccine microchip."

```{r eval = FALSE}

# Gtrends keyword searches
# Info about keyword searches: https://github.com/PMassicotte/gtrendsR/issues/268
k <- c( "covid vaccine",
        "covid vaccine near me",
        "covid vaccine safe", 
        "covid vaccine ingredients", 
        "covid vaccine pregnant", 
        "covid vaccine protect", 
        "covid vaccine side effects", 
        "covid vaccine microchip", 
        "covid vaccine dna", 
        "covid vaccine fetal", 
        "covid vaccine infertility", 
        "covid vaccine magnet")

```

The gtrendsR package was used to work with Google Trends Queries. This allowed us to look at the trends, or number of hits, for each of the 12 keyword searches. In addition, we studied the hit results in each of the 50 states and the District of Columbia. Trends data was pulled for three time periods: 1/1/21-9/20/21, 4/1/21-6/20/21, and 7/1/21-9/20/21 since vaccine availability varied by state. Furthermore, each element in "k" was renamed based on its index (hits.1, hits.2, ...hits.12) for code efficiency. 

```{r eval = FALSE }
get.hits.results <-  function(date){
    for (i in 1:length(k)){
          new_frame <- paste("Keyword",i,sep = "")
          assign(new_frame, gtrends(k[i], geo = "US",
                   time = date, low_search_volume = T)
                 )
    }
    
    hits_results <- Keyword1$interest_by_region %>%              
      left_join(Keyword2$interest_by_region, by = "location") %>%
      left_join(Keyword3$interest_by_region, by = "location") %>%
      left_join(Keyword4$interest_by_region, by = "location") %>%
      left_join(Keyword5$interest_by_region, by = "location") %>%
      left_join(Keyword6$interest_by_region, by = "location") %>%
      left_join(Keyword7$interest_by_region, by = "location") %>%
      left_join(Keyword8$interest_by_region, by = "location") %>%
      left_join(Keyword9$interest_by_region, by = "location") %>%
      left_join(Keyword10$interest_by_region, by = "location") %>%
      left_join(Keyword11$interest_by_region, by = "location") %>%
      left_join(Keyword12$interest_by_region, by = "location") %>%
      as_tibble() %>%
      select(c(1,2,6,10,14,18,22,26,30,34,38,42,46))
    
    hits_results %<>% rename( hits.1 = hits.x, 
                          hits.2 = hits.y,
                          hits.3 = hits.x.x,
                          hits.4 = hits.y.y,
                          hits.5 = hits.x.x.x,
                          hits.6 = hits.y.y.y,
                          hits.7 = hits.x.x.x.x,
                          hits.8 = hits.y.y.y.y,
                          hits.9 = hits.x.x.x.x.x,
                          hits.10 = hits.y.y.y.y.y,
                          hits.11 = hits.x.x.x.x.x.x,
                          hits.12 = hits.y.y.y.y.y.y)
    print(hits_results)  
    
}

hits.results.jan <- get.hits.results("2021-01-1 2021-09-20")
hits.results.june <- get.hits.results("2021-04-1 2021-06-20")
hits.results.sept <- get.hits.results("2021-07-1 2021-09-20")
```

```{r}
print(hits.results.jan) 
print(hits.results.june) 
print(hits.results.sept)
```

Next, a data frame was created to list the count of states that have a gtrends ranking present for the specified search term. 

```{r eval = FALSE}
#create a data frame that lists the count of states that have a gtrends ranking for the specified search term
get.search.terms <- function(hits_results){
  j <- c("hits.1", "hits.2", "hits.3", "hits.4", 
        "hits.5", "hits.6", "hits.7", "hits.8", 
        "hits.9", "hits.10","hits.11","hits.12")

  search_terms <- apply(!is.na(hits_results), 2, sum) %>%
    as_tibble() %>%
    slice_tail(n=12) %>%
    cbind(j,k) %>%
    relocate(value,.after = k)
    
  search_terms %<>% rename(var_name = j, search = k, num_states = value)
  
  print(search_terms)
}

search.terms.jan <- get.search.terms(hits.results.jan)
search.terms.june <- get.search.terms(hits.results.june) 
search.terms.sept <- get.search.terms(hits.results.sept)
```

```{r}
print(search.terms.jan)
print(search.terms.june)
print(search.terms.sept)
```
## 2. Vaccine Rates
```{r eval = FALSE, echo = FALSE}
## Use RSocrata to pull down CDC COVID vaccine data using their API
## Dataset information available here: https://dev.socrata.com/foundry/data.cdc.gov/unsk-b7fc
## https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-Jurisdi/unsk-b7fc

cdc.df <- read.socrata(
  "https://data.cdc.gov/resource/unsk-b7fc.json",
  app_token = "vUEGablI1SjS2eGix6O89iNgH",
  email     = "stacey.m.frank@gmail.com",
  password  = "fN7E27&3K0Uf"
)

```


```{r eval = FALSE, echo = FALSE}
##Data formatting/cleaning for CDC dataset

str(cdc.df)

apply(is.na(cdc.df), 2, sum)

cdc.df <- cdc.df %>% 
     mutate_at(c(4:80), as.numeric)

cdc.df$mmwr_week <- as.numeric(cdc.df$mmwr_week)

apply(is.na(cdc.df), 2, sum)
```


```{r eval = FALSE, echo = FALSE}
# Drop rows for territories and federal entities; only retain 50 states and Washington, DC (Google trends only has data for these entities)al = false

table(cdc.df$location)


attach(cdc.df)
cdc.df.50 <-  cdc.df[ which (location!= "BP2" & location!= "DD2" & location!= "GU" & location!= "IH2" & location!= "LTC" & location!= "MH" & location!= "AS" & location!= "FM" & location!= "MP" & location!= "RP" & location!= "US" & location!= "VA2" & location!= "VI" & location!= "PR"),]
detach(cdc.df)

table(cdc.df.50$location)
```


```{r eval = FALSE, echo = FALSE}
# Recode responses in CDC location variable so it matches the format used in Google Trends data, in preparation for joining datasets

cdc.df.50$location[cdc.df.50$location == "AK"] <- "Alaska"
cdc.df.50$location[cdc.df.50$location == "AL"] <- "Alabama"
cdc.df.50$location[cdc.df.50$location == "AR"] <- "Arkansas"
cdc.df.50$location[cdc.df.50$location == "AZ"] <- "Arizona"
cdc.df.50$location[cdc.df.50$location == "CA"] <- "California"
cdc.df.50$location[cdc.df.50$location == "CO"] <- "Colorado"
cdc.df.50$location[cdc.df.50$location == "CT"] <- "Connecticut"
cdc.df.50$location[cdc.df.50$location == "DC"] <- "District of Columbia"
cdc.df.50$location[cdc.df.50$location == "DE"] <- "Delaware"
cdc.df.50$location[cdc.df.50$location == "FL"] <- "Florida"
cdc.df.50$location[cdc.df.50$location == "GA"] <- "Georgia"
cdc.df.50$location[cdc.df.50$location == "HI"] <- "Hawaii"
cdc.df.50$location[cdc.df.50$location == "IA"] <- "Iowa"
cdc.df.50$location[cdc.df.50$location == "ID"] <- "Idaho"
cdc.df.50$location[cdc.df.50$location == "IL"] <- "Illinois"
cdc.df.50$location[cdc.df.50$location == "IN"] <- "Indiana"
cdc.df.50$location[cdc.df.50$location == "KS"] <- "Kansas"
cdc.df.50$location[cdc.df.50$location == "KY"] <- "Kentucky"
cdc.df.50$location[cdc.df.50$location == "LA"] <- "Louisiana"
cdc.df.50$location[cdc.df.50$location == "MA"] <- "Massachusetts"
cdc.df.50$location[cdc.df.50$location == "MD"] <- "Maryland"
cdc.df.50$location[cdc.df.50$location == "ME"] <- "Maine"
cdc.df.50$location[cdc.df.50$location == "MI"] <- "Michigan"
cdc.df.50$location[cdc.df.50$location == "MN"] <- "Minnesota"
cdc.df.50$location[cdc.df.50$location == "MO"] <- "Missouri"
cdc.df.50$location[cdc.df.50$location == "MS"] <- "Mississippi"
cdc.df.50$location[cdc.df.50$location == "MT"] <- "Montana"
cdc.df.50$location[cdc.df.50$location == "NC"] <- "North Carolina"
cdc.df.50$location[cdc.df.50$location == "ND"] <- "North Dakota"
cdc.df.50$location[cdc.df.50$location == "NE"] <- "Nebraska"
cdc.df.50$location[cdc.df.50$location == "NH"] <- "New Hampshire"
cdc.df.50$location[cdc.df.50$location == "NJ"] <- "New Jersey"
cdc.df.50$location[cdc.df.50$location == "NM"] <- "New Mexico"
cdc.df.50$location[cdc.df.50$location == "NV"] <- "Nevada"
cdc.df.50$location[cdc.df.50$location == "NY"] <- "New York"
cdc.df.50$location[cdc.df.50$location == "OH"] <- "Ohio"
cdc.df.50$location[cdc.df.50$location == "OK"] <- "Oklahoma"
cdc.df.50$location[cdc.df.50$location == "OR"] <- "Oregon"
cdc.df.50$location[cdc.df.50$location == "PA"] <- "Pennsylvania"
cdc.df.50$location[cdc.df.50$location == "RI"] <- "Rhode Island"
cdc.df.50$location[cdc.df.50$location == "SC"] <- "South Carolina"
cdc.df.50$location[cdc.df.50$location == "SD"] <- "South Dakota"
cdc.df.50$location[cdc.df.50$location == "TN"] <- "Tennessee"
cdc.df.50$location[cdc.df.50$location == "TX"] <- "Texas"
cdc.df.50$location[cdc.df.50$location == "UT"] <- "Utah"
cdc.df.50$location[cdc.df.50$location == "VA"] <- "Virginia"
cdc.df.50$location[cdc.df.50$location == "VT"] <- "Vermont"
cdc.df.50$location[cdc.df.50$location == "WA"] <- "Washington"
cdc.df.50$location[cdc.df.50$location == "WI"] <- "Wisconsin"
cdc.df.50$location[cdc.df.50$location == "WV"] <- "West Virginia"
cdc.df.50$location[cdc.df.50$location == "WY"] <- "Wyoming"

table(cdc.df.50$location)

```


```{r eval = FALSE}
# visualize doses administered over time for entire US

cdc.df.50 %>%
  group_by(date) %>%
  summarize(administered = sum(administered)) %>%
  ggplot() +
  geom_line(mapping = aes(x = date, y = administered))

```

Data for the vaccine and rates is acquired by using RSocrata to pull CDC COVID vaccine data through their API. After cleaning, two datasets are created for our vaccination dates of interest,vax.June21 and vax.Sept21. 

```{r, eval = FALSE}
## Create two datasets for our vaccination dates of interest

vax.June21 <- cdc.df.50 %>%
  filter(date == "2021-06-21")
vax.Sept21 <- cdc.df.50 %>%
  filter(date == "2021-09-21")

```

## 3. State-level Demographics
  Certain state-level demographic factors could potentially have an impact on our analysis. We turned to different sources for this information. Data of interest included state population counts, voter information, houshold income, age group, and race. 

  State population numbers were web scraped from Wikipedia using selector gadget (https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population). These state counts were then joined with the vax.June21 and vax.Sept21 frames created in Part 2. 
  

```{r eval = FALSE, echo = FALSE}

## Scrape state population info from Wikipedia. Turn into a data frame called state_pop

paths_allowed("https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population")
url <- read_html("https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population")  
nds <- html_nodes(url, xpath = '//td[(((count(preceding-sibling::*) + 1) = 3) and parent::*)]')
state <- html_text(nds)
state <- gsub("\n","",state)
state <- str_trim(state)
state <- state[-c(31,53:60)]

nds2 <- html_nodes(url, xpath = '//td[(((count(preceding-sibling::*) + 1) = 4) and parent::*)]')
population <- html_text(nds2)
population <- gsub("\n","",population)
population <- gsub(",","",population)
population <- population[-c(31,53:60)]

state_pop <- as_tibble(cbind(state,population))
state_pop <- state_pop %>% arrange(state)
```


```{r eval = FALSE, echo = FALSE}

## Join state population data from above with the June 21 and September 21 data frames

state_pop <- rename(state_pop, location = state)

vax.June21 <- vax.June21 %>%
  left_join(state_pop, by = "location")
  
vax.Sept21 <- vax.Sept21 %>%
  left_join(state_pop, by = "location")

vax.Sept21 %>%
  select(location, population, administered, admin_per_100k)
```

```{r echo = FALSE}

## Percent of population by state that have been fully vaccinated as of September 21

vax.Sept21 %>%
  select(location, series_complete_pop_pct) %>%
  arrange(series_complete_pop_pct)
```

  In addition, voter information was downloaded from Cook Political https://cookpolitical.com/2020-national-popular-vote-tracker. Unnecessary columns were deleted and columns of interest were renamed. Here, we are primarily interested in the share of republican voters in the 2020 election.  The final spreasheet was saved as vote.xlsx. 
  Median household income was downloaded from Census https://www2.census.gov/programs-surveys/cps/tables/time-series/historical-income-households/h08.xls and saved as med.income.xlsx. Unnecessary columns were deleted and columns of interest were selected: state(location) and median income(med.income). 
  Percent of state population by age group was pulled from https://datacenter.kidscount.org/data/tables/6538-adult-population-by-age-group#detailed/2/2-53/false/574,1729,37,871,870,573,869,36,868,867/117,2801,2802,2803/13515,13516. The raw excel data was downloaded. Columns from years 2011-2019 were deleted since we are focusing on the most recently available data, in this case 2020. The spread() function from the tidyr package was then used to reshape from long to wide so we can split up the categorical Age Group Variable into the 3 separate 18 to 24, 25 to 64, and Ages 65 and over variables. The final spreadsheet was saved as percent.age.xlsx.
  Race data was pulled as a csv file from the Current Population Survey. https://www.kff.org/other/state-indicator/population-distribution-by-race-ethnicity-cps/?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D 
It was then converted from CSV to xlsx, unnecessary columns were deleted, columns of interest were renamed, and reported percentages of <.01 were replaced with 0 (to make all cell values integers). Categories for American Indian/Alaska Native, Native Hawaiian/Other Pacific Islander, and Multiple Races were combined into a single 'Other' category. This was saved as State Race Data.xlsx.
  These four excel files were loaded into the FOCD Github public repository. They were then joined together in R and saved as the object "cov" (for covariates). Cov was then joined with the two CDC vaccine rate data collected in Part 2 (vax.June21 or vax.Sept21). 



```{r eval = FALSE, echo = FALSE}

## Get state percentages of Trump voters info. Source is https://cookpolitical.com/2020-national-popular-vote-tracker.

getwd() 
# /Users/ariannaschmid/Desktop/SURVMETH 727/FOCD
setwd("/Users/ariannaschmid/Desktop/SURVMETH 727")

percent.rep <- read_excel("vote.xlsx", sheet = "Sheet1")
percent.rep %<>% select (state,rep_percent) %>% rename (pct.vote.rep = rep_percent, location = state) %>% arrange(location)

 
## Get median household income info from 2018. Source is https://www2.census.gov/programs-surveys/cps/tables/time-series/historical-income-households/h08.xls

med.income <- read_excel("med.income.xlsx", range = cell_cols(1:2), col_names = c("location","med.income") )

## Get percent of state population by age group info. Source is https://datacenter.kidscount.org/data/tables/6538-adult-population-by-age-group#detailed/2/2-53/false/574,1729,37,871,870,573,869,36,868,867/117,2801,2802,2803/13515,13516

percent.age <- read_excel("percent.age.xlsx", 
                          col_names = c("location","age.group","pct.state.pop"))
percent.age %<>% spread(key = age.group, value = pct.state.pop) %>%
                 rename("pct.18.to.24" = "18 to 24", "pct.25.to.64" = "25 to 64","pct.65.over" = "Ages 65 and over")

percent.age$pct.18.to.24 <- as.numeric(percent.age$pct.18.to.24)
percent.age$pct.25.to.64 <- as.numeric(percent.age$pct.25.to.64)
percent.age$pct.65.over <- as.numeric(percent.age$pct.65.over)

#Get percent of state population by race/ethnic group. Source is 2020 Current Population Survey via the KFF:
#https://www.kff.org/other/state-indicator/population-distribution-by-race-ethnicity-cps/?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D

percent.race <- read_excel("C:/Users/sfrank/Box/JPSM/SURV727-Fundamentals of Computing and Data Display/FOCD RStudio/State Race Data.xlsx", 
                          col_names = TRUE, col_types = NULL)

## Join 3 sets from above together. These are some covariates for the regression model
cov <- percent.rep %>% full_join(med.income, by = "location") %>% full_join(percent.age, by = "location") %>% full_join(percent.race, by = "location")

## Join covariates from above with the June 21 and September 21 data frames; same as we did with state population info from Wikipedia

vax.June21 <- vax.June21 %>%
  left_join(cov, by = "location")
  
vax.Sept21 <- vax.Sept21 %>%
  left_join(cov, by = "location")


## Arianna's code to fix tables. Don't rerun.
vax.June21 %<>% select(-c(pct.vote.rep.x,med.income.x,pct.18.to.24.x,pct.25.to.64.x,pct.65.over.x,
                         )) 
vax.June21 %<>% rename(pct.vote.rep = pct.vote.rep.y, med.income = med.income.y, pct.18.to.24 = pct.18.to.24.y,
                       pct.25.to.64 = pct.25.to.64.y, pct.65.over = pct.65.over.y)

vax.Sept21 %<>% select(-c(pct.vote.rep.x,med.income.x,pct.18.to.24.x,pct.25.to.64.x,pct.65.over.x,
                         )) 
vax.Sept21 %<>% rename(pct.vote.rep = pct.vote.rep.y, med.income = med.income.y, pct.18.to.24 = pct.18.to.24.y,
                       pct.25.to.64 = pct.25.to.64.y, pct.65.over = pct.65.over.y)

```


```{r eval = FALSE, echo = FALSE}
## Replace NAs in gtrends hit rates data frames with zero (assuming there is no hit rate because there aren't enough searches, so functionally it's zero)

hits.results.jan[is.na(hits.results.jan)] = 0
hits.results.june[is.na(hits.results.june)] = 0
hits.results.sept[is.na(hits.results.sept)] = 0
```

  Finally, the three gtrends datasets from Part 1 (hits.results.jan, hits.results.june, hits.results.sept) are joined with the updated vax.June21 or vax.Sept21, depending on the dates the Trends are covering. A function called join.gtrends.vaccine accomplishes this and saves the 3 final data sets as Jan01.analysis, Sept21.analysis, and June21.analysis. Now they are ready for analysis. 

```{r eval = FALSE}

## This function joins the gtrends dataset with vaccine info dataset
join.gtrends.vaccine <- function (hits.results.month,vax.month){
  
  month.analysis <- vax.month %>% 
      select(location,date, admin_per_100k, series_complete_pop_pct,
             pct.vote.rep, med.income, pct.18.to.24, pct.25.to.64, pct.65.over, 
             pct.white, pct.black, pct.hispanic, pct.asian, pct.other.multiple) %>% 
        full_join(hits.results.month, by = "location") %>%
        arrange(location)
  
  print(month.analysis)

}

Jan01.analysis <- join.gtrends.vaccine(hits.results.jan,vax.Sept21)   
Sept21.analysis <- join.gtrends.vaccine(hits.results.sept,vax.Sept21)
June21.analysis <- join.gtrends.vaccine(hits.results.june,vax.June21)
```

# Analysis

## 1. Correlation Analysis

```{r eval = FALSE}

## This function pulls the correlations for all 3 data sets 
get.correlations <- function(month.analysis){
      #Loop for correlations for each search term
      j <- c("hits.1", "hits.2", 
      "hits.3", "hits.4", 
      "hits.5", "hits.6", 
      "hits.7", "hits.8", 
      "hits.9", "hits.10",
      "hits.11","hits.12")
    
      correlations <- data.frame(estimate=numeric(26), p.value=numeric(26))
    
      for(i in 15:ncol(month.analysis)){
        test <- cor.test(month.analysis[, i], month.analysis$series_complete_pop_pct)
        correlations$estimate[i] = test$estimate
        correlations$p.value[i] = test$p.value
      }
    
      correlations %<>%
        slice_tail(n=12) %>%
        cbind(j,k) %>%
        relocate(estimate, p.value,.after = k)
        
      correlations %<>% rename(var_name = j, search = k)
    
      print(correlations)

}

Jan01.correlations <- get.correlations(Jan01.analysis)
Sept21.correlations <- get.correlations(Sept21.analysis)
June21.correlations <- get.correlations(June21.analysis)

```

```{r}
##Plotting of correlations

#Jan-Sept Searches
# using series_complete_pop_pct as measure for state vaccination rate                
ggplot(Jan01.analysis) + geom_point(aes(hits.1, series_complete_pop_pct), color = '#24d0bc', size = 4) + 
      labs(y = "State % Pop. Completed Vax Series", x = "Jan-Sept Search Volume for 'COVID Vaccine'") +
      ggtitle("Searches for 'COVID Vaccine' are Strongly Correlated with State Vax Rates") + 
      theme_classic()

ggsave("covid.correlation.Jan.png")
```
```{r}

##Plotting of correlations continued

#July-September Searches
# using series_complete_pop_pct as measure for state vaccination rate                
ggplot(Sept21.analysis) + geom_point(aes(hits.1, series_complete_pop_pct), color = '#24d0bc', size = 4) + 
      labs(y = "State % Pop. Completed Vax Series", x = "July-Sept Search Volume for 'COVID Vaccine'") +
      ggtitle("July-Sept Searches for 'COVID Vaccine' Relationship with State Vax Rates") + 
      theme_classic()

ggsave("covid.correlation.Sept.png")
```
## 2. Regression Analysis

```{r}

# Plotting and regression analysis

Jan01.analysis %>% select(series_complete_pop_pct, pct.vote.rep,med.income,
                          pct.18.to.24,pct.25.to.64,pct.65.over) %>% 
                          plot()

##percent republican and median income seem to have a linear relationship with series_complete_pop_pct; age does not seem to have any relationship with vax rates

Jan01.analysis %>% select(series_complete_pop_pct, pct.white,pct.black,pct.hispanic,pct.asian,pct.other.multiple) %>% 
                          plot()

##None of the race variables seem to be related to vax rates


Jan01.analysis %>% select(series_complete_pop_pct, hits.1,hits.2,hits.3,hits.4) %>% 
                          plot()

#Hits1 is related; other plots are widely scattered

Jan01.analysis %>% select(series_complete_pop_pct, hits.5,hits.6,hits.7,hits.8) %>% 
                          plot()

#Hits5 has some relationship; others not so much

Jan01.analysis %>% select(series_complete_pop_pct, hits.9,hits.10,hits.11,hits.12) %>% 
                          plot()

#No strong relationships here


##histogram of outcome variable

hist(Jan01.analysis$series_complete_pop_pct)
hist(Jan01.analysis$admin_per_100k)


##Linear model

model1 <- lm(series_complete_pop_pct ~ pct.vote.rep + pct.white + pct.black + hits.1 + hits.2 + hits.3 + hits.4 + hits.5 + hits.6 + hits.7 + hits.8 + hits.9 + hits.10 + hits.11 + hits.12 , data = Jan01.analysis)

summary(model1)

#Check that residuals are normally distributed

hist(residuals(model1))

#Check for homoskedasticity in residual variances (looks ok)

plot(fitted(model1), residuals(model1))
abline(h = 0, lty = 2)

#Linear model with interaction
#When adding interaction between hits.1 and % who voted republican, the main effects and the interaction are all not significant. Need to think about what that means...

model2 <- lm(series_complete_pop_pct ~ pct.vote.rep + pct.black + hits.1  + hits.1*pct.vote.rep, data = Jan01.analysis)

summary(model2)
```

```{r eval = FALSE}
save.image(file = "shared_work_space.RData")
```

# References
